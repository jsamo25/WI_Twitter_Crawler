{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 1. Install the twitter library in python"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tweepy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Install library for JSON"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install simplejson","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Install sentiment analysis library"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install textblob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Streaming tweets and perform some data analysis\n"},{"metadata":{},"cell_type":"markdown","source":"### Setting up and running a streaming crawler"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tweepy\nimport simplejson as json\nfrom tweepy import OAuthHandler\nfrom tweepy import Stream\nfrom tweepy.streaming import StreamListener\nfrom textblob import TextBlob\n \n#Complete with your keys \n\nconsumer_key = '8LbgPJVK5AgR1vKcvCssNyKkp'\nconsumer_secret = 'PPrIa7y3xcK4aktfqqEUeQuk2K8BzwmYsXoBZkmCaVygqW3J9M'\naccess_token = '191181457-zejYmLuj85d5XOzRxNX2tFIncNvqIEwnhqmzVjCb'\naccess_secret = 'LfQ7P7I1e47as04eptD2er246ZmJdhkQiLol6ARkC6nTP'\n \nauth = OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_secret)\n \n\nclass MyListener(StreamListener):\n    \n    def __init__(self, api=None):\n        super(StreamListener, self).__init__()\n        self.num_tweets = 0\n\n    def on_data(self, data):\n        try:\n            with open('MyFile.json', 'a') as f:\n                if json.loads(data).get('place'):\n                    #if json.loads(data)['place']['country'] == 'United States':\n                        f.write(data) # This will store the whole JSON data in the file, you can perform some JSON filters\n                        twitter_text = json.loads(data)['text'] # You can also print your tweets here\n                        print(twitter_text)\n                        print()\n                        self.num_tweets += 1 \n                        # Just to limit the number of tweets collected to check the \n                        # program at the beginning, then increase the limit\n                        if self.num_tweets < 250: \n                            return True\n                        else:\n                            return False\n        except BaseException as e:\n            print(\"Error on_data: %s\" % str(e))\n        return True\n\n \n    def on_error(self, status):\n        print('Error :', status.place)\n        return False\n    \ntwitter_stream = Stream(auth, MyListener())\ntwitter_stream.filter(track=[\"coronavirus\"], languages=['en']) # Add your keywords and other filters\n\nprint('_______ End _______')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Store the JSON data in a CSV for analysing"},{"metadata":{"trusted":true},"cell_type":"code","source":"import simplejson as json\n\n# Create the CSV file\nwith open (\"MyFile.csv\", 'w') as csv:\n    # Write the title of the columns (features) that you want to store in the CSV file\n    csv.write(\"id,\" + \"created_at,\" + \"text,\" + \"country,\" +\"country_code,\" + \"followers,\" + \"friends\" + \"\\n\")\n    \n    # Copy the data from the JSON file\n    with open('MyFile.json', 'r') as jsonfile:\n        for tweet in jsonfile: \n            data = json.loads(tweet)\n            \n            # The int values should be converted to strings\n            csv.write(str(data[\"id\"]) + \",\")\n            csv.write(str(data[\"created_at\"]) + \",\")\n            csv.write((str(data[\"text\"]).replace(\"\\n\",\"\").replace(\",\",\"\")) + \",\")\n            csv.write(str(data[\"place\"][\"country\"]) + \",\")\n            csv.write(str(data[\"place\"][\"country_code\"]) + \",\")\n            csv.write(str(data[\"user\"][\"followers_count\"]) + \",\")\n            csv.write(str(data[\"user\"][\"friends_count\"]))\n            csv.write(\"\\n\")\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the previous CSV into pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ntweets = pd.read_csv('MyFile.csv', index_col=0, encoding='ISO-8859-1')\ntweets.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysing the polarity of the tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob\npolarity, subjectivity = 0, 0\n\ncount = 0\nfor text in tweets.text:\n    analysis = TextBlob(text)\n    polarity += analysis.sentiment[0]\n    subjectivity += analysis.sentiment[1]\n    count +=1\n    \nprint (\"Average Polarity:\", polarity/count)\nprint (\"Average Subjectivity:\",subjectivity/count)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generating a wordcloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install wordcloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install plotly\n!pip install regexp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Your own analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets = pd.read_csv('MyFile.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tweets.drop('Unnamed: 0', axis=1, inplace=True)\n# tweets.drop('Title', axis=1, inplace=True)\ntweets = tweets[~tweets['text'].isnull()]\n\ndef preprocess(text):\n    text = text.str.replace(\"(<br/>)\", \"\")\n    text = text.str.replace('(<a).*(>).*(</a>)', '')\n    text = text.str.replace('(&amp)', '')\n    text = text.str.replace('(&gt)', '')\n    text = text.str.replace('(&lt)', '')\n    text = text.str.replace('(\\xa0)', ' ')\n    text = text.str.replace(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\")\n    return text\n\ntweets['text'] = preprocess(tweets['text'])\n\ntweets['polarity'] = tweets['text'].map(lambda text: TextBlob(text).sentiment.polarity)\ntweets['review_len'] = tweets['text'].astype(str).apply(len)\ntweets['word_count'] = tweets['text'].apply(lambda x: len(str(x).split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\nimport re\n\ntext = tweets.text.values\n\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'white',\n    stopwords = STOPWORDS).generate(str(text))\nfig = plt.figure(\n    figsize = (30, 20),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'gaussian')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('TOP 5 tweets with Positive (= +1) sentiment polarity: \\n')\n\ntry:\n    cl = tweets.loc[tweets.polarity == 1, ['text']].sample(5).values\n    for c in cl:\n        print(c[0])\nexcept:\n    print(\"[Error: not enought tweets to create a TOP 5] \\n \\n\")\n    print(\"[Showing the most positive tweets]: \\n\\n\")\n    \n    cl = tweets.loc[tweets.polarity == 1, ['text']].values\n    for c in cl:\n        print(c[0],\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('TOP 5 tweets with Neutral (=0) sentiment polarity: \\n')\n\ntry:\n    cl = tweets.loc[tweets.polarity == 0, ['text']].sample(5).values\n    for c in cl:\n        print(c[0])\nexcept:\n    print(\"[Error: not enought tweets to create a TOP 5] \\n \\n\")\n    print(\"[Showing the most positive tweets]: \\n\\n\")\n    \n    cl = tweets.loc[tweets.polarity == 0, ['text']].values\n    for c in cl:\n        print(c[0],\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('TOP 5 tweets with Negative (= -1) sentiment polarity: \\n')\n\ntry:\n    cl = tweets.loc[tweets.polarity == -1, ['text']].sample(5).values\n    for c in cl:\n        print(c[0])\nexcept:\n    print(\"[Error: not enought tweets to create a TOP 5] \\n \\n\")\n    cl = tweets.loc[tweets.polarity == -1, ['text']].values\n    \n    if cl.size > 0:\n        print(\"[Showing the most negative tweets:] \\n\\n\")\n    \n        cl = tweets.loc[tweets.polarity ==-1, ['text']].values\n        for c in cl:\n            print(c[0],\"\\n\")\n        \n    else:\n        print (\"[Error: Could not find any tweet with polarity equal to -1]\\n\")\n        print (\"[printing some of the most negative tweeets (<0)]\\n\\n\")\n        \n        cl = tweets.loc[tweets.polarity < 0, ['text']].sample(5).values\n        for c in cl:\n            print(c[0],\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.histogram(tweets, x=\"country\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\ntweets_country_1, tweets_country_2, tweets_country_3= [], [], []\npolarity_c1, polarity_c2, polarity_c3= [], [], []\n\n\nwhile i < len(tweets):\n    if tweets[\"country\"][i] == \"United States\":\n        tweets_country_1.append(tweets[\"text\"][i])\n    elif tweets[\"country\"][i] == \"United Kingdom\":\n        tweets_country_2.append(tweets[\"text\"][i])\n    elif tweets[\"country\"][i] == \"Malaysia\":\n        tweets_country_3.append(tweets[\"text\"][i])\n    i += 1\n\n\ncount = 0\nfor text in tweets_country_1:\n    analysis = TextBlob(text)\n    polarity_c1.append(analysis.sentiment[0])\nfor text in tweets_country_2:\n    analysis = TextBlob(text)\n    polarity_c2.append(analysis.sentiment[0])\nfor text in tweets_country_3:\n    analysis = TextBlob(text)\n    polarity_c3.append(analysis.sentiment[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nimport numpy as np\n\nx0 = polarity_c1\nx1 = polarity_c2 \nx2 = polarity_c3\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(x=x0, name=\"USA\"))\nfig.add_trace(go.Histogram(x=x1, name=\"UK\"))\nfig.add_trace(go.Histogram(x=x2, name=\"Malaysia\"))\n\n# Overlay both histograms\nfig.update_layout(barmode='overlay')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.65)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = tweets[\"country\"]\ncountries = list(dict.fromkeys(countries))\npolarity_per_country, tweets_country, polarities= [], [], []\n\nfor c in countries: \n    i=0\n    while i < len(tweets):\n        if tweets[\"country\"][i] == c:\n            tweets_country.append(tweets[\"text\"][i])\n        i += 1\n\n    count = 0\n    for text in tweets_country:\n        analysis = TextBlob(text)\n        polarity += analysis.sentiment[0]\n        count +=1\n    polarity = polarity/count\n    polarities.append(polarity)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nimport pandas as pd\n\nfig = go.Figure(data=go.Choropleth(\n    locationmode= \"country names\",\n    locations = countries,\n    z = polarities,\n    text = countries,\n    colorscale = 'rainbow',\n    autocolorscale=False,\n    reversescale=True,\n    marker_line_color='darkgray',\n    marker_line_width=0.5,\n    colorbar_tickprefix = '',\n    colorbar_title = 'polarities',\n))\n\nfig.update_layout(\n    title_text='Sentiment Analysis',\n    geo=dict(\n        showframe=False,\n        showcoastlines=False,\n        projection_type='equirectangular'\n    ),\n    annotations = [dict(\n        x=0.55,\n        y=0.1,\n        xref='paper',\n        yref='paper',\n        text='Source: Twitter Data, Hashtag #coronavirus',\n        showarrow = False\n    )]\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}